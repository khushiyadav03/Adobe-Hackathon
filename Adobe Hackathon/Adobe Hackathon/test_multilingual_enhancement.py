#!/usr/bin/env python3
"""
Test Multilingual Enhancement for Adobe Hackathon
Comprehensive testing of multilingual capabilities
"""

import os
import json
import time
import logging
from pathlib import Path
from typing import List, Dict

# Import enhanced pipeline
from src.enhanced_multilingual_pipeline import EnhancedMultilingualPipeline

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MultilingualEnhancementTester:
    """Test multilingual enhancement capabilities"""
    
    def __init__(self):
        self.pipeline = EnhancedMultilingualPipeline()
        self.test_results = {}
    
    def test_language_detection(self):
        """Test language detection capabilities"""
        print("\nğŸ” TESTING LANGUAGE DETECTION")
        print("=" * 50)
        
        test_cases = [
            ("ç¬¬1ç«  ã¯ã˜ã‚ã«", "ja"),
            ("ç¬¬ä¸€ç«  å¼•è¨€", "zh"),
            ("ì œ1ì¥ ì„œë¡ ", "ko"),
            ("Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„ Ù…Ù‚Ø¯Ù…Ø©", "ar"),
            ("à¤…à¤§à¥à¤¯à¤¾à¤¯ 1 à¤ªà¤°à¤¿à¤šà¤¯", "hi"),
            ("CapÃ­tulo 1 IntroducciÃ³n", "es"),
            ("Chapitre 1 Introduction", "fr"),
            ("Kapitel 1 EinfÃ¼hrung", "de"),
            ("Chapter 1 Introduction", "en"),
            ("Capitolo 1 Introduzione", "it"),
            ("CapÃ­tulo 1 IntroduÃ§Ã£o", "pt"),
            ("Hoofdstuk 1 Inleiding", "nl"),
            ("Kapitel 1 Inledning", "sv"),
            ("Kapitel 1 Innledning", "no"),
            ("Kapitel 1 Indledning", "da"),
            ("RozdziaÅ‚ 1 Wprowadzenie", "pl"),
            ("Kapitola 1 Ãšvod", "cs"),
            ("Kapitola 1 Ãšvod", "sk"),
            ("Fejezet 1 BevezetÃ©s", "hu"),
            ("Capitol 1 Introducere", "ro"),
            ("Ğ“Ğ»Ğ°Ğ²Ğ° 1 Ğ’ÑŠĞ²ĞµĞ´ĞµĞ½Ğ¸Ğµ", "bg"),
            ("Poglavlje 1 Uvod", "hr"),
            ("Poglavje 1 Uvod", "sl"),
            ("à¸šà¸—à¸—à¸µà¹ˆ 1 à¸šà¸—à¸™à¸³", "th"),
            ("ÎšÎµÏ†Î¬Î»Î±Î¹Î¿ 1 Î•Î¹ÏƒÎ±Î³Ï‰Î³Î®", "el"),
            ("×¤×¨×§ 1 ××‘×•×", "he")
        ]
        
        correct_detections = 0
        results = {}
        
        for text, expected_lang in test_cases:
            detected_lang = self.pipeline.language_detector.detect_language(text)
            is_correct = detected_lang == expected_lang
            status = "âœ…" if is_correct else "âŒ"
            
            print(f"{status} '{text}' -> Expected: {expected_lang}, Detected: {detected_lang}")
            
            if is_correct:
                correct_detections += 1
            
            results[text] = {
                'expected': expected_lang,
                'detected': detected_lang,
                'correct': is_correct
            }
        
        accuracy = (correct_detections / len(test_cases)) * 100
        print(f"\nğŸ“Š Language Detection Accuracy: {accuracy:.1f}% ({correct_detections}/{len(test_cases)})")
        
        self.test_results['language_detection'] = {
            'accuracy': accuracy,
            'results': results
        }
        
        return accuracy
    
    def test_heading_patterns(self):
        """Test multilingual heading pattern recognition"""
        print("\nğŸ“‹ TESTING MULTILINGUAL HEADING PATTERNS")
        print("=" * 50)
        
        test_cases = [
            # English
            ("Chapter 1: Introduction", "en", "Title"),
            ("1.1 Background", "en", "H1"),
            ("1.1.1 Research Methods", "en", "H2"),
            ("Appendix A: Data", "en", "H1"),
            
            # Japanese
            ("ç¬¬1ç«  ã¯ã˜ã‚ã«", "ja", "Title"),
            ("1.1 èƒŒæ™¯", "ja", "H1"),
            ("1.1.1 ç ”ç©¶æ–¹æ³•", "ja", "H2"),
            ("ä»˜éŒ²A ãƒ‡ãƒ¼ã‚¿", "ja", "H1"),
            
            # Chinese
            ("ç¬¬ä¸€ç«  å¼•è¨€", "zh", "Title"),
            ("1.1 èƒŒæ™¯", "zh", "H1"),
            ("1.1.1 ç ”ç©¶æ–¹æ³•", "zh", "H2"),
            ("é™„å½•A æ•°æ®", "zh", "H1"),
            
            # Korean
            ("ì œ1ì¥ ì„œë¡ ", "ko", "Title"),
            ("1.1 ë°°ê²½", "ko", "H1"),
            ("1.1.1 ì—°êµ¬ ë°©ë²•", "ko", "H2"),
            ("ë¶€ë¡A ë°ì´í„°", "ko", "H1"),
            
            # Arabic
            ("Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„ Ù…Ù‚Ø¯Ù…Ø©", "ar", "Title"),
            ("1.1 Ø®Ù„ÙÙŠØ©", "ar", "H1"),
            ("1.1.1 Ø·Ø±Ù‚ Ø§Ù„Ø¨Ø­Ø«", "ar", "H2"),
            ("Ù…Ù„Ø­Ù‚ Ø£ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "ar", "H1"),
            
            # Hindi
            ("à¤…à¤§à¥à¤¯à¤¾à¤¯ 1 à¤ªà¤°à¤¿à¤šà¤¯", "hi", "Title"),
            ("1.1 à¤ªà¥ƒà¤·à¥à¤ à¤­à¥‚à¤®à¤¿", "hi", "H1"),
            ("1.1.1 à¤¶à¥‹à¤§ à¤µà¤¿à¤§à¤¿à¤¯à¤¾à¤‚", "hi", "H2"),
            ("à¤ªà¤°à¤¿à¤¶à¤¿à¤·à¥à¤Ÿ à¤ à¤¡à¥‡à¤Ÿà¤¾", "hi", "H1"),
            
            # Spanish
            ("CapÃ­tulo 1: IntroducciÃ³n", "es", "Title"),
            ("1.1 Antecedentes", "es", "H1"),
            ("1.1.1 MÃ©todos de InvestigaciÃ³n", "es", "H2"),
            ("ApÃ©ndice A: Datos", "es", "H1"),
            
            # French
            ("Chapitre 1: Introduction", "fr", "Title"),
            ("1.1 Contexte", "fr", "H1"),
            ("1.1.1 MÃ©thodes de Recherche", "fr", "H2"),
            ("Annexe A: DonnÃ©es", "fr", "H1"),
            
            # German
            ("Kapitel 1: EinfÃ¼hrung", "de", "Title"),
            ("1.1 Hintergrund", "de", "H1"),
            ("1.1.1 Forschungsmethoden", "de", "H2"),
            ("Anhang A: Daten", "de", "H1")
        ]
        
        correct_patterns = 0
        results = {}
        
        for text, language, expected_level in test_cases:
            # Test pattern recognition
            is_heading = self.pipeline.heading_patterns.is_heading(text, language)
            detected_level = self.pipeline.heading_patterns.extract_heading_level(text, language)
            
            is_correct = detected_level == expected_level
            status = "âœ…" if is_correct else "âŒ"
            
            print(f"{status} [{language.upper()}] '{text}' -> Expected: {expected_level}, Detected: {detected_level}")
            
            if is_correct:
                correct_patterns += 1
            
            results[f"{language}_{text}"] = {
                'language': language,
                'text': text,
                'expected_level': expected_level,
                'detected_level': detected_level,
                'is_heading': is_heading,
                'correct': is_correct
            }
        
        accuracy = (correct_patterns / len(test_cases)) * 100
        print(f"\nğŸ“Š Heading Pattern Accuracy: {accuracy:.1f}% ({correct_patterns}/{len(test_cases)})")
        
        self.test_results['heading_patterns'] = {
            'accuracy': accuracy,
            'results': results
        }
        
        return accuracy
    
    def test_text_normalization(self):
        """Test multilingual text normalization"""
        print("\nğŸ“ TESTING TEXT NORMALIZATION")
        print("=" * 50)
        
        test_cases = [
            ("ç¬¬ï¼‘ç« ã€€ã¯ã˜ã‚ã«", "ja", "ç¬¬1ç«  ã¯ã˜ã‚ã«"),
            ("ç¬¬ä¸€ç« ã€€å¼•è¨€", "zh", "ç¬¬ä¸€ç«  å¼•è¨€"),
            ("ì œï¼‘ì¥ã€€ì„œë¡ ", "ko", "ì œ1ì¥ ì„œë¡ "),
            ("Ø§Ù„ÙØµÙ„ã€€Ø§Ù„Ø£ÙˆÙ„ã€€Ù…Ù‚Ø¯Ù…Ø©", "ar", "Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„ Ù…Ù‚Ø¯Ù…Ø©"),
            ("à¤…à¤§à¥à¤¯à¤¾à¤¯ã€€à¥§ã€€à¤ªà¤°à¤¿à¤šà¤¯", "hi", "à¤…à¤§à¥à¤¯à¤¾à¤¯ 1 à¤ªà¤°à¤¿à¤šà¤¯"),
            ("CapÃ­tuloã€€1:ã€€IntroducciÃ³n", "es", "CapÃ­tulo 1: IntroducciÃ³n"),
            ("Chapitreã€€1:ã€€Introduction", "fr", "Chapitre 1: Introduction"),
            ("Kapitelã€€1:ã€€EinfÃ¼hrung", "de", "Kapitel 1: EinfÃ¼hrung")
        ]
        
        correct_normalizations = 0
        results = {}
        
        for original, language, expected in test_cases:
            normalized = self.pipeline.text_normalizer.normalize(original, language)
            is_correct = normalized == expected
            status = "âœ…" if is_correct else "âŒ"
            
            print(f"{status} [{language.upper()}] '{original}' -> '{normalized}'")
            
            if is_correct:
                correct_normalizations += 1
            
            results[f"{language}_{original}"] = {
                'language': language,
                'original': original,
                'expected': expected,
                'normalized': normalized,
                'correct': is_correct
            }
        
        accuracy = (correct_normalizations / len(test_cases)) * 100
        print(f"\nğŸ“Š Text Normalization Accuracy: {accuracy:.1f}% ({correct_normalizations}/{len(test_cases)})")
        
        self.test_results['text_normalization'] = {
            'accuracy': accuracy,
            'results': results
        }
        
        return accuracy
    
    def test_feature_extraction(self):
        """Test multilingual feature extraction"""
        print("\nğŸ”§ TESTING FEATURE EXTRACTION")
        print("=" * 50)
        
        test_cases = [
            ("ç¬¬1ç«  ã¯ã˜ã‚ã«", "ja", 16.0, "Arial", True, False, 1),
            ("ç¬¬ä¸€ç«  å¼•è¨€", "zh", 16.0, "SimSun", True, False, 1),
            ("ì œ1ì¥ ì„œë¡ ", "ko", 16.0, "Malgun Gothic", True, False, 1),
            ("Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„ Ù…Ù‚Ø¯Ù…Ø©", "ar", 16.0, "Arial", True, False, 1),
            ("à¤…à¤§à¥à¤¯à¤¾à¤¯ 1 à¤ªà¤°à¤¿à¤šà¤¯", "hi", 16.0, "Arial", True, False, 1),
            ("CapÃ­tulo 1: IntroducciÃ³n", "es", 16.0, "Arial", True, False, 1),
            ("Chapitre 1: Introduction", "fr", 16.0, "Arial", True, False, 1),
            ("Kapitel 1: EinfÃ¼hrung", "de", 16.0, "Arial", True, False, 1)
        ]
        
        successful_extractions = 0
        results = {}
        
        for text, language, font_size, font_name, is_bold, is_italic, page_num in test_cases:
            try:
                features = self.pipeline.feature_extractor.extract_features(
                    text, font_size, font_name, is_bold, is_italic, page_num
                )
                
                # Check if language was detected correctly
                detected_lang = features.get('language', 'unknown')
                is_correct = detected_lang == language
                status = "âœ…" if is_correct else "âŒ"
                
                print(f"{status} [{language.upper()}] '{text}' -> Language: {detected_lang}")
                
                if is_correct:
                    successful_extractions += 1
                
                results[f"{language}_{text}"] = {
                    'language': language,
                    'text': text,
                    'detected_language': detected_lang,
                    'features': features,
                    'correct': is_correct
                }
                
            except Exception as e:
                print(f"âŒ Error extracting features for '{text}': {e}")
                results[f"{language}_{text}"] = {
                    'language': language,
                    'text': text,
                    'error': str(e),
                    'correct': False
                }
        
        accuracy = (successful_extractions / len(test_cases)) * 100
        print(f"\nğŸ“Š Feature Extraction Success Rate: {accuracy:.1f}% ({successful_extractions}/{len(test_cases)})")
        
        self.test_results['feature_extraction'] = {
            'accuracy': accuracy,
            'results': results
        }
        
        return accuracy
    
    def test_multilingual_support_info(self):
        """Test multilingual support information"""
        print("\nğŸŒ TESTING MULTILINGUAL SUPPORT INFO")
        print("=" * 50)
        
        support_info = self.pipeline.get_multilingual_support_info()
        
        print(f"ğŸ“Š Supported Languages: {support_info['supported_languages']}")
        print(f"ğŸ¯ Overall Accuracy: {support_info['overall_accuracy']:.1%}")
        print(f"ğŸ“ˆ Multilingual Accuracy Range: {support_info['multilingual_accuracy_range']['min']:.1%} - {support_info['multilingual_accuracy_range']['max']:.1%}")
        print(f"ğŸ“Š Average Multilingual Accuracy: {support_info['multilingual_accuracy_range']['average']:.1%}")
        
        print("\nğŸ“‹ Language Details:")
        for lang, info in support_info['language_details'].items():
            print(f"  {lang.upper()}: {info['accuracy']:.1%} accuracy ({info['support_level']} support)")
        
        self.test_results['multilingual_support'] = support_info
        
        return support_info
    
    def test_with_sample_pdfs(self):
        """Test with existing Adobe sample PDFs"""
        print("\nğŸ“„ TESTING WITH SAMPLE PDFS")
        print("=" * 50)
        
        # Test with existing Adobe PDFs
        sample_pdfs = [
            "test_pdfs/Adobe-India-Hackathon25-main/Challenge_1a/sample_dataset/pdfs/file01.pdf",
            "test_pdfs/Adobe-India-Hackathon25-main/Challenge_1a/sample_dataset/pdfs/file02.pdf",
            "test_pdfs/Adobe-India-Hackathon25-main/Challenge_1a/sample_dataset/pdfs/file03.pdf"
        ]
        
        results = {}
        
        for pdf_path in sample_pdfs:
            if os.path.exists(pdf_path):
                print(f"\nğŸ“„ Testing: {os.path.basename(pdf_path)}")
                
                try:
                    # Test Round 1A
                    start_time = time.time()
                    result = self.pipeline.generate_multilingual_round1a_output(pdf_path)
                    processing_time = time.time() - start_time
                    
                    print(f"  âœ… Processing time: {processing_time:.3f}s")
                    print(f"  ğŸŒ Language detected: {result.get('language_detected', 'unknown')}")
                    print(f"  ğŸ“‹ Headings found: {len(result.get('headings', []))}")
                    print(f"  ğŸ“Š Estimated accuracy: {result.get('multilingual_features', {}).get('estimated_accuracy', 0):.1%}")
                    
                    results[pdf_path] = {
                        'success': True,
                        'processing_time': processing_time,
                        'language_detected': result.get('language_detected', 'unknown'),
                        'headings_count': len(result.get('headings', [])),
                        'estimated_accuracy': result.get('multilingual_features', {}).get('estimated_accuracy', 0)
                    }
                    
                except Exception as e:
                    print(f"  âŒ Error: {e}")
                    results[pdf_path] = {
                        'success': False,
                        'error': str(e)
                    }
            else:
                print(f"  âŒ PDF not found: {pdf_path}")
        
        self.test_results['sample_pdf_testing'] = results
        
        return results
    
    def run_comprehensive_test(self):
        """Run comprehensive multilingual testing"""
        print("ğŸŒ MULTILINGUAL ENHANCEMENT COMPREHENSIVE TESTING")
        print("=" * 60)
        
        # Run all tests
        language_detection_accuracy = self.test_language_detection()
        heading_pattern_accuracy = self.test_heading_patterns()
        text_normalization_accuracy = self.test_text_normalization()
        feature_extraction_accuracy = self.test_feature_extraction()
        support_info = self.test_multilingual_support_info()
        sample_pdf_results = self.test_with_sample_pdfs()
        
        # Calculate overall accuracy
        test_accuracies = [
            language_detection_accuracy,
            heading_pattern_accuracy,
            text_normalization_accuracy,
            feature_extraction_accuracy
        ]
        
        overall_accuracy = sum(test_accuracies) / len(test_accuracies)
        
        # Print summary
        print("\n" + "=" * 60)
        print("ğŸ† MULTILINGUAL ENHANCEMENT TEST SUMMARY")
        print("=" * 60)
        
        print(f"ğŸ” Language Detection: {language_detection_accuracy:.1f}%")
        print(f"ğŸ“‹ Heading Patterns: {heading_pattern_accuracy:.1f}%")
        print(f"ğŸ“ Text Normalization: {text_normalization_accuracy:.1f}%")
        print(f"ğŸ”§ Feature Extraction: {feature_extraction_accuracy:.1f}%")
        print(f"ğŸ“Š Overall Test Accuracy: {overall_accuracy:.1f}%")
        print(f"ğŸŒ Supported Languages: {support_info['supported_languages']}")
        print(f"ğŸ¯ Maintained English Accuracy: {support_info['overall_accuracy']:.1%}")
        
        # Save results
        with open('multilingual_test_results.json', 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ Test results saved to: multilingual_test_results.json")
        
        return self.test_results

def main():
    """Main testing function"""
    tester = MultilingualEnhancementTester()
    results = tester.run_comprehensive_test()
    
    print("\n" + "=" * 60)
    print("âœ… MULTILINGUAL ENHANCEMENT TESTING COMPLETED")
    print("=" * 60)

if __name__ == "__main__":
    main() 